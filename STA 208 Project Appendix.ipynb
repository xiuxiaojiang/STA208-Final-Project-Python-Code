{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ffa7ab",
   "metadata": {},
   "source": [
    "### 7.  Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce8981",
   "metadata": {},
   "source": [
    "**Python code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9392fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns \n",
    "sns.set(context=\"notebook\", palette=\"Spectral\", style = 'darkgrid' ,font_scale = 1.5, color_codes=True)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import RidgeCV, LassoCV,ElasticNetCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import arange\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import shapiro\n",
    "from scipy import stats\n",
    "import plotnine as p9\n",
    "from mizani.breaks import date_breaks\n",
    "from mizani.formatters import date_format\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac30a06",
   "metadata": {},
   "source": [
    "**4.1 Data cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53919ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44da470",
   "metadata": {},
   "source": [
    "4.1.1 Missing value\n",
    "\n",
    "*Get the percentage of NA values for each column*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_freq = df.apply(lambda x: sum(x.isna()) / len(x), axis=0)\n",
    "na_freq = (\n",
    "    na_freq[na_freq>0]\n",
    "    .reset_index()\n",
    "    .rename(columns={'index': 'Feature', 0: 'Missing %'})\n",
    "    .sort_values(by='Missing %', ascending=False)\n",
    ")\n",
    "na_freq['Feature'] = pd.Categorical(na_freq['Feature'], categories=na_freq['Feature'].tolist())\n",
    "(\n",
    "    p9.ggplot(na_freq, p9.aes('Feature', 'Missing %'))\n",
    "    + p9.geom_bar(stat='identity')\n",
    "    + p9.scale_y_continuous(labels=lambda x: [\"{:.0%}\".format(v) for v in x])\n",
    "    + p9.theme(\n",
    "        axis_text_x = p9.element_text(angle=35,hjust=1),\n",
    "        figure_size = (7, 3)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03377abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(df['Neighborhood'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c8812",
   "metadata": {},
   "source": [
    "*Find the reason for missing: missing at random, or missing for a reason*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb62c3",
   "metadata": {},
   "source": [
    "Missing because the component does not exist in the house:\n",
    "* PoolQC\n",
    "* MiscFeature\n",
    "* Alley\n",
    "* Fence\n",
    "* FireplaceQu\n",
    "* GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond\n",
    "* BsmtExposure (NA and \"No\" have different meaning)\n",
    "* BsmtFinType1, BsmtFinType2, BsmtCond, BsmtQual\n",
    "\n",
    "Missing at random\n",
    "* LotFrontage\n",
    "* MasVnrType & MasVnrArea\n",
    "* Electrical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee64313",
   "metadata": {},
   "source": [
    "*Example of missing due to non-existance of a house component*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaca9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two helper functions for calculating percentiles\n",
    "def q05(x):\n",
    "    return np.quantile(x, 0.05)\n",
    "def q95(x):\n",
    "    return np.quantile(x, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When there is no pool (PoolArea == 0), PoolQC is missing\n",
    "(\n",
    "    df.groupby('PoolQC', dropna=False)\n",
    "    .agg({\n",
    "        'PoolArea': [q05, np.median, q95],\n",
    "        'SalePrice': [q05, np.median, q95]\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb4dc4",
   "metadata": {},
   "source": [
    "*Confirm missing at random*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LotFrontage:\n",
    "# Missing vs non-missing: similar sale price and year built\n",
    "#    (although there are some difference in median sale price)\n",
    "# So we consider this as missing at random\n",
    "# Consider removing this column\n",
    "# Since this column is highly correlated with LotArea, we may consider removing this feature.\n",
    "\n",
    "(\n",
    "    df.groupby(df['LotFrontage'].isna())\n",
    "    .agg({\n",
    "        'LotFrontage': [len, q05, np.median, q95],\n",
    "        'SalePrice': [q05, np.median, q95],\n",
    "        'YearBuilt': [q05, np.median, q95],\n",
    "        'LotArea': [q05, np.median, q95],\n",
    "        'LotShape': lambda x: x.value_counts()\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9860f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    p9.ggplot(df, p9.aes('LotArea', 'LotFrontage', color='LotShape'))\n",
    "    + p9.geom_point(alpha=0.5)\n",
    "    + p9.xlim(0, 20000)\n",
    "    + p9.ylim(0, 180)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197189ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MasVnrType and MasVnrArea\n",
    "\n",
    "# When MasVnrType is missing, the corresponding MasVnrArea value is also missing\n",
    "# No systematic difference in the values in year_built and neighborhood\n",
    "#    between MasVnrType missing and non-missing groups\n",
    "\n",
    "# Fill in \"None\" and \"0\" for Type and Area, because that is the most observed values\n",
    "\n",
    "(\n",
    "    df.groupby('MasVnrType', dropna=False)\n",
    "    .agg({\n",
    "        'MasVnrArea': [len, q05, np.median, q95],\n",
    "        'SalePrice': np.median,\n",
    "        'YearBuilt': [q05, np.median, q95],\n",
    "        'Neighborhood': lambda x: x.unique()\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da0e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.groupby(df['MasVnrType'].isna())\n",
    "    .agg({\n",
    "        'MasVnrArea': [len, q05, np.median, q95],\n",
    "        'SalePrice': np.median,\n",
    "        'YearBuilt': [q05, np.median, q95],\n",
    "        'Neighborhood': lambda x: x.unique()\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electrical\n",
    "\n",
    "# There is only one missing data for the column \"Electrical\"\n",
    "# And the \"Utilities\" column says it has all utilities.\n",
    "\n",
    "# Since only one row, it's safe to remove this data\n",
    "\n",
    "df[df['Electrical'].isna()]['Utilities']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b2e474",
   "metadata": {},
   "source": [
    "*Pre-process the missing values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db740e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f4e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = [\n",
    "    'PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',\n",
    "    'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "    'BsmtExposure', 'BsmtCond', 'BsmtQual'\n",
    "]\n",
    "# 'GarageYrBlt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629318de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageYrBlt'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical_feats] = df[categorical_feats].fillna('Not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1fb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = df['BsmtFinType1'].isna() & df['BsmtFinType2'].isna()\n",
    "df.loc[sel, 'BsmtFinType1'] = 'Not exist'\n",
    "df.loc[sel, 'BsmtFinType2'] = 'Not exist'\n",
    "df.loc[df['BsmtFinType2'].isna(), 'BsmtFinType2'] = 'Unf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93885123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='LotFrontage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46fdc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['MasVnrType'].isna(), 'MasVnrType'] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f436ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['MasVnrArea'].isna(), 'MasVnrArea'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00cc629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After process missing values\n",
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c3e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7469d0",
   "metadata": {},
   "source": [
    "**4.1.2 Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data and testing data\n",
    "# x and y\n",
    "x = df.drop([\"logSalePrice\",\"SalePrice\"],axis=1) # create x variables, drop the independent variable\n",
    "y = df.logSalePrice\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,random_state = 0,test_size=0.25)\n",
    "\n",
    "#log transform SalePrice\n",
    "x = df.SalePrice\n",
    "sns.set_style('whitegrid')\n",
    "sns.distplot(x)\n",
    "plt.show()\n",
    "\n",
    "df['SalePrice_log'] = np.log(df.SalePrice)\n",
    "x = df.SalePrice_log\n",
    "sns.distplot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLS model\n",
    "model = sm.OLS(y, x, missing='drop')\n",
    "model_result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlying in X\n",
    "# normalized residuals\n",
    "model_norm_residuals = model_result.get_influence().resid_studentized_internal\n",
    "# leverage, from statsmodels internals\n",
    "model_leverage = model_result.get_influence().hat_matrix_diag\n",
    "# cook's distance, from statsmodels internals\n",
    "model_cooks = model_result.get_influence().cooks_distance[0]\n",
    "\n",
    "# Residuals and leverage plot\n",
    "plot_lm_4 = plt.figure();\n",
    "plt.scatter(model_leverage, model_norm_residuals, alpha=0.5);\n",
    "sns.regplot(model_leverage, model_norm_residuals,\n",
    "              scatter=False,\n",
    "              ci=False,\n",
    "              lowess=True,\n",
    "              line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8});\n",
    "plot_lm_4.axes[0].set_xlim(0, max(model_leverage)+0.01)\n",
    "plot_lm_4.axes[0].set_ylim(-8, 8)\n",
    "plot_lm_4.axes[0].set_title('Residuals vs Leverage')\n",
    "plot_lm_4.axes[0].set_xlabel('Leverage')\n",
    "plot_lm_4.axes[0].set_ylabel('Standardized Residuals');\n",
    "\n",
    "# annotations\n",
    "leverage_top_3 = np.flip(np.argsort(model_cooks), 0)[:3]\n",
    "for i in leverage_top_3:\n",
    "    plot_lm_4.axes[0].annotate(i,\n",
    "                        xy=(model_leverage[i],\n",
    "                        model_norm_residuals[i]));\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131056ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlying in y\n",
    "#At alpha = 0.05, Single tail\n",
    "t= stats.t.ppf(1-0.05/(2 * Train.shape[0]), Train.shape[0]-Train.shape[1])\n",
    "\n",
    "p = sns.scatterplot(y_pred,residuals)\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.ylim(-5,5)\n",
    "plt.xlim(10,14)\n",
    "p = sns.lineplot([10,14],[0,0],color='blue')\n",
    "p = plt.title('Residuals vs fitted values')\n",
    "p = sns.lineplot([10,14],[t,t],color='green')\n",
    "p = sns.lineplot([10,14],[-t,-t],color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd514a03",
   "metadata": {},
   "source": [
    "**4.2 Assumptions checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearity\n",
    "p = sns.scatterplot(y_pred,residuals)\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.ylim(-0.5,0.5)\n",
    "plt.xlim(10,14)\n",
    "p = sns.lineplot([10,14],[0,0],color='blue')\n",
    "p = plt.title('Residuals vs fitted values')\n",
    "\n",
    "# Normality of error terms: QQ plot\n",
    "sm.qqplot(model_result.resid, line='s');\n",
    "p = plt.title('QQ Plot of residuals')\n",
    "\n",
    "# Independence of the error terms:\n",
    "import statsmodels.api as sm\n",
    "# autocorrelation\n",
    "sm.graphics.tsa.plot_acf(residuals, lags=40)\n",
    "plt.title('Residuals autocorrelation')\n",
    "plt.show()\n",
    "\n",
    "#Constant variance of the error terms / homoscedastic:\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "name = ['F statistic', 'p-value']\n",
    "test = sms.het_goldfeldquandt(residuals, x_train)\n",
    "lzip(name, test)\n",
    "\n",
    "#Multicollinearity (Correlation)\n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = x.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(x.values, i)\n",
    "                          for i in range(len(x.columns))]\n",
    "  \n",
    "#print(vif_data)\n",
    "VIF_sort= vif_data.sort_values(by='VIF',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf907387",
   "metadata": {},
   "source": [
    "**4.3 Feature Engineering**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de68840b",
   "metadata": {},
   "source": [
    "4.3.1 Categorical variable encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a6a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.groupby(['YrSold', 'Neighborhood'])\n",
    "    .agg({'SalePrice': np.mean})\n",
    "    .reset_index()\n",
    "    .pivot(index='Neighborhood', columns='YrSold')\n",
    ").style.format('{:.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0406b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_categorical_feats = ['MSSubClass', 'OverallQual', 'OverallCond', 'YrSold']\n",
    "for col in num_to_categorical_feats:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "basement_feats = set(['BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2'])\n",
    "feats_to_combine = set(['Condition1', 'Condition2', 'Exterior1st', 'Exterior2nd'])\n",
    "one_hot_feats = set(df.dtypes[df.dtypes == 'object'].index) - basement_feats - feats_to_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basement_feats contains two categorical and two numerical\n",
    "print(\n",
    "    'Number of categorical features: ',\n",
    "    len(one_hot_feats) + len(feats_to_combine) + len(basement_feats) / 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb0c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(df['BsmtFinSF1'] == 0), sum(df['BsmtFinSF2'] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00935d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.get_dummies(df, columns=one_hot_feats, drop_first=True, dummy_na=True)\n",
    "df = pd.get_dummies(df, columns=one_hot_feats, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6719b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_type = set(df['BsmtFinType1'].unique()).union(set(df['BsmtFinType2'].unique()))\n",
    "# add columns to df\n",
    "for bt in basement_type:\n",
    "    df['BsmtFinSF_' + bt] = 0\n",
    "\n",
    "# fill in square feet values into the columns\n",
    "for r in range(len(df)):\n",
    "    col = 'BsmtFinSF_' + df.loc[r, 'BsmtFinType1']\n",
    "    if df.loc[r, 'BsmtFinType1'] == 'Not exist':\n",
    "        df.loc[r, col] = 1\n",
    "    else:\n",
    "        df.loc[r, col] = df.loc[r, 'BsmtFinSF1']\n",
    "    \n",
    "    # Fill in the number for the second BsmtFinType.\n",
    "    col = 'BsmtFinSF_' + df.loc[r, 'BsmtFinType2']\n",
    "    if df.loc[r, 'BsmtFinType2'] == 'Not exist':\n",
    "        df.loc[r, col] = 1\n",
    "    else:\n",
    "        # If the col is the same as the prev col, we just add the numbers together.\n",
    "        df.loc[r, col] += df.loc[r, 'BsmtFinSF2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(df, feat1, feat2, feat_prefix):\n",
    "    feat_levels = set(df[feat1].unique()).union(set(df[feat2].unique()))\n",
    "    print('Feature levels = ', feat_levels)\n",
    "    # create new columns for each level of the feature\n",
    "    # and initialize to all 0's\n",
    "    for l in feat_levels:\n",
    "        df[feat_prefix + l] = '0'\n",
    "    \n",
    "    # fill in value 1 to the relevant columns\n",
    "    for r in range(len(df)):\n",
    "        col = feat_prefix + df.loc[r, feat1]\n",
    "        df.loc[r, col] = '1'\n",
    "        col = feat_prefix + df.loc[r, feat2]\n",
    "        df.loc[r, col] = '1'\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_spelling = {'Wd Shng': 'Wd Sdng', 'CmentBd': 'CemntBd'}\n",
    "df['Exterior1st'].replace(wrong_spelling, inplace=True)\n",
    "df['Exterior2nd'].replace(wrong_spelling, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine_features(df, 'Condition1', 'Condition2', 'Condition_')\n",
    "df = combine_features(df, 'Exterior1st', 'Exterior2nd', 'Exterior_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the feature transformed result\n",
    "df[['BsmtFinSF_ALQ', 'BsmtFinSF_Rec', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2']].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Condition_Feedr'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef5bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Condition1', 'Condition2']].iloc[[974, 1003, 88]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_example_df = pd.get_dummies(\n",
    "    df[['Condition1', 'Condition2']].iloc[[974, 1003, 88]])\n",
    "\n",
    "dummy_example2_df = pd.concat([\n",
    "    dummy_example_df['Condition1_Feedr'] | dummy_example_df['Condition2_Feedr'],\n",
    "    dummy_example_df['Condition1_RRAn'] | dummy_example_df['Condition2_RRAn']\n",
    "], axis=1).rename(columns={0: 'Condition_Feedr', 1: 'Condition_RRAn'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(11,3), gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "sns.heatmap(dummy_example_df, annot=True, cbar=False, ax=ax[0])\n",
    "sns.heatmap(dummy_example2_df, annot=True, cbar=False, ax=ax[1])\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_ylabel('Sample ID')\n",
    "    ax[i].set_xlabel('Feature Name')\n",
    "    # ax[i].xticks(rotation=10)\n",
    "\n",
    "ax[0].set_title('(a) One-hot Encoding')\n",
    "ax[1].set_title('(b) Two-hot Encoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf1fe84",
   "metadata": {},
   "source": [
    "4.3.2 Nonlinearity transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MoSold_sq'] = df['MoSold'] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ccf5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearBuilt_sq'] = (df['YearBuilt'] - 1850) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325494cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'col': df.columns, 'type': list(df.dtypes)}).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ba9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YearBuilt: nonlinear relation\n",
    "(\n",
    "    p9.ggplot(df, p9.aes(x='YearBuilt', y='SalePrice'))\n",
    "    + p9.geom_point(alpha=0.4)\n",
    "    + p9.scale_y_log10()\n",
    "    + p9.geom_smooth(method='loess', color='tab:blue')\n",
    "    + p9.theme(figure_size=(6, 3))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5afaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MoSold: nonlinear relation\n",
    "(\n",
    "    p9.ggplot(df, p9.aes(x='MoSold', y='SalePrice', group='MoSold'))\n",
    "    + p9.geom_boxplot()\n",
    "    + p9.scale_y_log10()\n",
    "    + p9.scale_x_discrete(limits=np.arange(1,13))\n",
    "    # + p9.geom_smooth(method='loess', color='tab:blue')\n",
    "    + p9.theme(figure_size=(7, 4)) + p9.facet_wrap('~ YrSold')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92784577",
   "metadata": {},
   "source": [
    "4.3.3 Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BedroomAbvGr*GarageCars'] = df['BedroomAbvGr'] * df['GarageCars']\n",
    "df['BedroomAbvGr*FullBath'] = df['BedroomAbvGr'] * df['FullBath']\n",
    "df['GrLivArea*LotArea'] = df['GrLivArea'] * df['LotArea']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc28845",
   "metadata": {},
   "source": [
    "**Building models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba2b5c",
   "metadata": {},
   "source": [
    "Elastic Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import RidgeCV, LassoCV,ElasticNetCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import arange\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv('train_processed.csv')\n",
    "print(Train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = list(set(Train.columns) - set(['logSalePrice', 'SalePrice']))\n",
    "df_normalized = Train.copy()\n",
    "df_normalized[feats] = (Train[feats] - Train[feats].mean()) / Train[feats].std()\n",
    "# df_normalized['logSalePrice'] = df['logSalePrice']\n",
    "df_normalized['SalePrice'] = Train['SalePrice'] / 1000000  # convert the unit to millions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dda0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(\n",
    "    df, feats, target,\n",
    "    alphas = [.1, .5, .7, .9, .95, .99, 1], is_log_transformed = True,\n",
    "    random_state=1000\n",
    "):\n",
    "    \n",
    "    # Train-test split. Use 30% as testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[feats], df[target], test_size=0.3, random_state=random_state)\n",
    "\n",
    "    # Elastic Net cross-validation\n",
    "    model = ElasticNetCV(cv = 10,alphas = alphas,random_state = random_state, n_jobs = -1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Create a data frame to store how MSE changes with alpha (regularization strength)\n",
    "    mse_path_df = pd.DataFrame({\n",
    "        'alpha': model.alphas_,\n",
    "        'mse': np.mean(model.mse_path_, axis=1)\n",
    "    })\n",
    "\n",
    "    # Predict on test data\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    # If log transform is used, we transform the data back to the original unit\n",
    "    if is_log_transformed:\n",
    "        pred_test = np.exp(pred_test) / 1000000  # in million dollar\n",
    "        y_test = np.exp(y_test) / 1000000  # in million dollar\n",
    "    \n",
    "    # Calculate RMSE and MAPE\n",
    "    rmse = np.sqrt(np.mean(np.square(pred_test - y_test)))\n",
    "    mape = np.mean(np.abs(pred_test - y_test) / y_test)\n",
    "    \n",
    "    return {\n",
    "        'mse_path': mse_path_df,\n",
    "        'pred_test': pred_test,\n",
    "        'X_test': X_test,  # return X_test for debugging purpose\n",
    "        'y_test': y_test,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape,\n",
    "        'elasticnet_cv': model  # store the whole elasticnet_cv object for easier exploration later\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas= np.linspace(0.001**3,0.005,500)\n",
    "#tcopy = Train.copy()\n",
    "res = train_and_predict(df_normalized, feats,'logSalePrice',alphas = alphas,is_log_transformed = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c9977",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(res['elasticnet_cv'].coef_ != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705726ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['elasticnet_cv'].alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(res):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Scatter plot of the prediction\n",
    "    plt.subplot(221)\n",
    "    plt.plot(res['pred_test'], res['y_test'], '.')\n",
    "    plt.xlabel('Predicted Sale Price')\n",
    "    plt.ylabel('True Sale Price')\n",
    "    \n",
    "    # use get_xlim for both x and y to draw \"x=y\" line\n",
    "    plt.plot(plt.gca().get_xlim(), plt.gca().get_xlim())\n",
    "    \n",
    "    # Residual plot\n",
    "    plt.subplot(222)\n",
    "    plt.plot(res['pred_test'], res['y_test'] - res['pred_test'], '.')\n",
    "    plt.xlabel('Predicted Sale Price')\n",
    "    plt.ylabel('Residual')\n",
    "    \n",
    "    # plot a horizontal line\n",
    "    plt.plot(plt.gca().get_xlim(), [0, 0])\n",
    "\n",
    "    # LASSO: mse vs penalty strength\n",
    "    plt.subplot(212)\n",
    "    plt.plot(res['mse_path']['alpha'], res['mse_path']['mse'], '.-')\n",
    "    plt.xlabel('Penalty Strength')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.grid()\n",
    "    print('Test RMSE: {:.3f} million, or {:.2f}k'.format(res['rmse'], res['rmse'] * 1000))\n",
    "    print('Test MAPE: {:.2%}'.format(res['mape']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dcb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe1c466",
   "metadata": {},
   "source": [
    "Final Model Using Optimized Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_normalized[feats], df_normalized['logSalePrice'], test_size=0.3, random_state=1000)\n",
    "# elastic net using optimized alpha\n",
    "model = ElasticNet(alpha=res['elasticnet_cv'].alpha_, l1_ratio=0.5)\n",
    "model.fit(X_train,y_train)\n",
    "# predict data using elastic net model\n",
    "y_pred = model.predict(X_test)\n",
    "print (\"Test MSE - Elastic Net Regression:\",((mean_squared_error(y_test, y_pred ))))\n",
    "print (\"Elastic Net Score (R squared) :\",((ElasticNet.score(model, X_test,y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set L to be number of coefficients\n",
    "L = len(res['elasticnet_cv'].coef_)\n",
    "nonzero_idx = []\n",
    "coefs = []\n",
    "for i in range(L):\n",
    "    if res['elasticnet_cv'].coef_[i] != 0:\n",
    "        # append index i if coef is 0\n",
    "        nonzero_idx = np.append(nonzero_idx,i)\n",
    "        coefs = np.append(coefs,res['elasticnet_cv'].coef_[i])\n",
    "# find column names    \n",
    "tcolnames = []       \n",
    "for col in df_normalized[feats].columns:\n",
    "    tcolnames = np.append(tcolnames,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = nonzero_idx.shape[0]\n",
    "nz_colnames = []\n",
    "for i in range(nz):\n",
    "    # append non-zero coefficient names\n",
    "    nz_colnames = np.append(nz_colnames,tcolnames[int(nonzero_idx[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6074d911",
   "metadata": {},
   "source": [
    "LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotnine as p9\n",
    "from sklearn.linear_model import Lasso, LassoCV, lasso_path, enet_path, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8219ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeca34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "\n",
    "feats = list(set(df.columns) - set(['logSalePrice', 'SalePrice']))\n",
    "df_normalized = df.copy()\n",
    "df_normalized[feats] = (df[feats] - df[feats].mean()) / df[feats].std()\n",
    "# df_normalized['logSalePrice'] = df['logSalePrice']\n",
    "df_normalized['SalePrice'] = df['SalePrice'] / 1000000  # convert the unit to millions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7fdcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_normalized[feats]\n",
    "y = df_normalized['logSalePrice']\n",
    "\n",
    "alphas = 10 ** np.arange(-3.5, 2, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e46cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_lasso, coefs_lasso, _ = lasso_path(X, y, alphas=alphas)\n",
    "alphas_enet, coefs_enet, _ = enet_path(\n",
    "    X, y, l1_ratio=0.2,\n",
    "    alphas=alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51f10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs(coefs_lasso[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a897cf0",
   "metadata": {},
   "source": [
    "Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee16005",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_ridge = 10 ** np.arange(-3.5, 2, 0.01)\n",
    "clf = Ridge()\n",
    "coefs_ridge = np.empty((X.shape[1], len(alphas_ridge)))\n",
    "for i in range(len(alphas_ridge)):\n",
    "    clf.set_params(alpha=alphas_ridge[i])\n",
    "    clf.fit(X, y)\n",
    "    coefs_ridge[:, i] = list(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523bd07",
   "metadata": {},
   "source": [
    "Barplot for Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db51a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = pd.DataFrame({\n",
    "    'RMSE': np.array([31.8,30.83,32.68]),\n",
    "    'MAPE %': np.array([10.19,9.61,9.73]),\n",
    "    'Model': ['Ridge','ElasticNet','LASSO']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e830c",
   "metadata": {},
   "source": [
    "Model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "sns.set(style=\"ticks\")\n",
    "ax = sns.barplot(x=\"Model\", y=\"RMSE\", data = model_comparison)\n",
    "ax.set_ylim(30,35)\n",
    "ax.bar_label(ax.containers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "sns.set(style=\"ticks\")\n",
    "ax = sns.barplot(x=\"Model\", y=\"MAPE %\", data = model_comparison)\n",
    "ax.set_ylim(9,11)\n",
    "ax.bar_label(ax.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935c3af",
   "metadata": {},
   "source": [
    "**5.2 Coefficient Path Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed78d15",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(50):\n",
    "    plt.subplot(5,10,i+1)\n",
    "    var_id = i\n",
    "    plt.plot(np.log(alphas_lasso), coefs_lasso[var_id, :])\n",
    "    plt.plot(np.log(alphas_enet), coefs_enet[var_id, :])\n",
    "    plt.plot(np.log(alphas_ridge), coefs_ridge[var_id, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353318c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_id = 14\n",
    "plt.plot(-np.log(alphas_lasso), coefs_lasso[var_id, :], label='LASSO')\n",
    "plt.plot(-np.log(alphas_enet), coefs_enet[var_id, :], label='ENet')\n",
    "plt.plot(-np.log(alphas_ridge), coefs_ridge[var_id, :], label='Ridge')\n",
    "plt.title('Number of Bedroom Above Grade')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe0a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_id = 32\n",
    "plt.plot(alphas_lasso, coefs_lasso[var_id, :], label='LASSO')\n",
    "plt.plot(alphas_enet, coefs_enet[var_id, :], label='ENet')\n",
    "plt.plot(alphas_ridge, coefs_ridge[var_id, :], label='Ridge')\n",
    "plt.title('RoofStyle_Mansard')\n",
    "plt.gca().set_xscale('log')\n",
    "plt.gca().invert_xaxis()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b26a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, sharex=True, figsize=(6, 10))\n",
    "for var_id in range(20):\n",
    "    ax[0].plot(alphas_lasso, coefs_lasso[var_id, :])\n",
    "    ax[0].text(alphas_lasso[-1], coefs_lasso[var_id, -1], str(var_id))\n",
    "    ax[0].set_title('LASSO')\n",
    "    \n",
    "for var_id in range(20):\n",
    "    ax[1].plot(alphas_enet, coefs_enet[var_id, :])\n",
    "    ax[1].set_title('Elastic Net')\n",
    "\n",
    "for var_id in range(20):\n",
    "    ax[2].plot(alphas_ridge, coefs_ridge[var_id, :])\n",
    "    ax[2].set_title('Ridge')\n",
    "\n",
    "# Because x axis is shared, change one x axis will affect all subplots\n",
    "ax[2].set_xscale('log')\n",
    "ax[2].invert_xaxis()\n",
    "ax[2].set_xlabel('Regularization Strength ($\\\\alpha$)')\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_ylabel('Coefficient')\n",
    "\n",
    "# Add lines to show first non-zero coefficient\n",
    "idx_1st_non_zero = np.where(coefs_lasso[0:20, :].sum(axis=0))[0][0]\n",
    "alpha_1st_non_zero = alphas_lasso[idx_1st_non_zero]\n",
    "ax[0].axvline(x=alpha_1st_non_zero, linestyle='--')\n",
    "\n",
    "idx_1st_non_zero = np.where(coefs_enet[0:20, :].sum(axis=0))[0][0]\n",
    "alpha_1st_non_zero = alphas_enet[idx_1st_non_zero]\n",
    "ax[1].axvline(x=alpha_1st_non_zero, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea47874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path_horizontal(\n",
    "    var_id_list, feat_name, ylim=(0, 0.2), legend=True, figsize=(10,4)\n",
    "):\n",
    "    fig, ax = plt.subplots(1, 3, sharex=True, sharey=True,\n",
    "                           figsize=figsize)\n",
    "    # fig.suptitle('Feature Coefficient Path Comparison for Three Models')\n",
    "    for var_id in var_id_list:\n",
    "        ax[0].plot(alphas_lasso, coefs_lasso[var_id, :], label=feat_name[var_id])\n",
    "        # ax[0].text(alphas_lasso[-1], coefs_lasso[var_id, -1], str(var_id))\n",
    "        ax[0].set_title('LASSO')\n",
    "        ax[0].set_ylim(ylim)\n",
    "\n",
    "    for var_id in var_id_list:\n",
    "        ax[1].plot(alphas_enet, coefs_enet[var_id, :], label=feat_name[var_id])\n",
    "        ax[1].set_title('Elastic Net')\n",
    "        ax[1].set_ylim(ylim)\n",
    "\n",
    "    for var_id in var_id_list:\n",
    "        ax[2].plot(alphas_ridge, coefs_ridge[var_id, :], label=feat_name[var_id])\n",
    "        ax[2].set_title('Ridge')\n",
    "        ax[2].set_ylim(ylim)\n",
    "\n",
    "    # Because x axis is shared, change one x axis will affect all subplots\n",
    "    ax[2].set_xscale('log')\n",
    "    ax[2].invert_xaxis()\n",
    "    \n",
    "    # Set axis labels\n",
    "    ax[0].set_ylabel('Coefficient')\n",
    "    for i in range(3):\n",
    "        ax[i].set_xlabel('Regularization Strength ($\\\\alpha$)')\n",
    "        if legend:\n",
    "            ax[i].legend()\n",
    "\n",
    "    # Add lines to show first non-zero coefficient\n",
    "    idx_1st_non_zero = np.where(coefs_lasso[var_id_list, :].sum(axis=0))[0][0]\n",
    "    alpha_1st_non_zero = alphas_lasso[idx_1st_non_zero]\n",
    "    ax[0].axvline(x=alpha_1st_non_zero, linestyle='--')\n",
    "\n",
    "    idx_1st_non_zero = np.where(coefs_enet[var_id_list, :].sum(axis=0))[0][0]\n",
    "    alpha_1st_non_zero = alphas_enet[idx_1st_non_zero]\n",
    "    ax[1].axvline(x=alpha_1st_non_zero, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf54b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path_vertical(\n",
    "    var_id_list, feat_name, ylim=(0, 0.2), legend=True, figsize=(6, 10)\n",
    "):\n",
    "    \n",
    "    fig, ax = plt.subplots(3, 1, sharex=True, figsize=figsize)\n",
    "    fig.suptitle('Feature Coefficient Path')\n",
    "    for var_id in var_id_list:\n",
    "        ax[0].plot(alphas_lasso, coefs_lasso[var_id, :], label=feat_name[var_id])\n",
    "        # ax[0].text(alphas_lasso[-1], coefs_lasso[var_id, -1], str(var_id))\n",
    "        ax[0].set_title('LASSO')\n",
    "        ax[0].set_ylim(ylim)\n",
    "\n",
    "    for var_id in var_id_list:\n",
    "        ax[1].plot(alphas_enet, coefs_enet[var_id, :], label=feat_name[var_id])\n",
    "        ax[1].set_title('Elastic Net')\n",
    "        ax[1].set_ylim(ylim)\n",
    "\n",
    "    for var_id in var_id_list:\n",
    "        ax[2].plot(alphas_ridge, coefs_ridge[var_id, :], label=feat_name[var_id])\n",
    "        ax[2].set_title('Ridge')\n",
    "        ax[2].set_ylim(ylim)\n",
    "\n",
    "    # Because x axis is shared, change one x axis will affect all subplots\n",
    "    ax[2].set_xscale('log')\n",
    "    ax[2].invert_xaxis()\n",
    "    ax[2].set_xlabel('Regularization Strength ($\\\\alpha$)')\n",
    "\n",
    "    for i in range(3):\n",
    "        ax[i].set_ylabel('Coefficient')\n",
    "        if legend:\n",
    "            ax[i].legend()\n",
    "\n",
    "    # Add lines to show first non-zero coefficient\n",
    "    idx_1st_non_zero = np.where(coefs_lasso[var_id_list, :].sum(axis=0))[0][0]\n",
    "    alpha_1st_non_zero = alphas_lasso[idx_1st_non_zero]\n",
    "    ax[0].axvline(x=alpha_1st_non_zero, linestyle='--')\n",
    "\n",
    "    idx_1st_non_zero = np.where(coefs_enet[var_id_list, :].sum(axis=0))[0][0]\n",
    "    alpha_1st_non_zero = alphas_enet[idx_1st_non_zero]\n",
    "    ax[1].axvline(x=alpha_1st_non_zero, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd46420",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df_normalized['GrLivArea'], df_normalized['1stFlrSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8665c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df_normalized['GrLivArea'], df_normalized['2ndFlrSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82665b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df_normalized['1stFlrSF'], df_normalized['2ndFlrSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05527432",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_id_list = [129,250,238]\n",
    "plot_path_horizontal(var_id_list, feats, figsize=(10,3), ylim=(-0.005, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_id_list = np.arange(20)\n",
    "plot_path_horizontal(var_id_list, feats, figsize=(10,3), ylim=(-0.1, 0.25), legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c685421",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, X.columns[i])  for i in range(len(X.columns)) if 'Area' in X.columns[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a36d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, X.columns[i])  for i in range(len(X.columns)) if 'SF' in X.columns[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd07b014",
   "metadata": {},
   "source": [
    "**5.3 Feature Coefficient Stability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import plotnine as p9\n",
    "from mizani.breaks import date_breaks\n",
    "from mizani.formatters import date_format\n",
    "\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['PoolArea'] > 0) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68baedc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "\n",
    "feats = list(set(df.columns) - set(['logSalePrice', 'SalePrice']))\n",
    "df_normalized = df.copy()\n",
    "df_normalized[feats] = (df[feats] - df[feats].mean()) / df[feats].std()\n",
    "# df_normalized['logSalePrice'] = df['logSalePrice']\n",
    "df_normalized['SalePrice'] = df['SalePrice'] / 1000000  # convert the unit to millions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfc2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(\n",
    "    df, feats, target, is_log_transformed=True,\n",
    "    alphas=10 ** np.arange(-3.5, -2.8, 0.01),\n",
    "    random_state=1000\n",
    "):\n",
    "    \n",
    "    # Train-test split. Use 30% as testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[feats], df[target], test_size=0.3, random_state=random_state)\n",
    "\n",
    "    # Lasso cross-validation\n",
    "    lasso_cv = LassoCV(cv=10, random_state=random_state, alphas=alphas, n_jobs=-1)\n",
    "    lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "    # Create a data frame to store how MSE changes with alpha (regularization strength)\n",
    "    mse_path_df = pd.DataFrame({\n",
    "        'alpha': lasso_cv.alphas_,\n",
    "        'mse': np.mean(lasso_cv.mse_path_, axis=1)\n",
    "    })\n",
    "\n",
    "    # Predict on test data\n",
    "    pred_test = lasso_cv.predict(X_test)\n",
    "    \n",
    "    # If log transform is used, we transform the data back to the original unit\n",
    "    if is_log_transformed:\n",
    "        pred_test = np.exp(pred_test) / 1000000  # in million dollar\n",
    "        y_test = np.exp(y_test) / 1000000  # in million dollar\n",
    "    \n",
    "    # Calculate RMSE and MAPE\n",
    "    rmse = np.sqrt(np.mean(np.square(pred_test - y_test)))\n",
    "    mape = np.mean(np.abs(pred_test - y_test) / y_test)\n",
    "    \n",
    "    return {\n",
    "        'mse_path': mse_path_df,\n",
    "        'pred_test': pred_test,\n",
    "        'X_test': X_test,  # return X_test for debugging purpose\n",
    "        'y_test': y_test,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape,\n",
    "        'lasso_cv': lasso_cv  # store the whole lasso_cv object for easier exploration later\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(res):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Scatter plot of the prediction\n",
    "    plt.subplot(221)\n",
    "    plt.plot(res['pred_test'], res['y_test'], '.')\n",
    "    plt.xlabel('Predicted Sale Price')\n",
    "    plt.ylabel('True Sale Price')\n",
    "    \n",
    "    # use get_xlim for both x and y to draw \"x=y\" line\n",
    "    plt.plot(plt.gca().get_xlim(), plt.gca().get_xlim())\n",
    "    \n",
    "    # Residual plot\n",
    "    plt.subplot(222)\n",
    "    plt.plot(res['pred_test'], res['y_test'] - res['pred_test'], '.')\n",
    "    plt.xlabel('Predicted Sale Price')\n",
    "    plt.ylabel('Residual')\n",
    "    \n",
    "    # plot a horizontal line\n",
    "    plt.plot(plt.gca().get_xlim(), [0, 0])\n",
    "\n",
    "    # LASSO: mse vs penalty strength\n",
    "    plt.subplot(212)\n",
    "    plt.plot(res['mse_path']['alpha'], res['mse_path']['mse'], '.-')\n",
    "    plt.xlabel('Penalty Strength')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.grid()\n",
    "    print('Test RMSE: {:.3f} million, or {:.2f}k'.format(res['rmse'], res['rmse'] * 1000))\n",
    "    print('Test MAPE: {:.2%}'.format(res['mape']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f445a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coef_df = pd.DataFrame({\n",
    "    'feat_name': res['lasso_cv'].feature_names_in_,\n",
    "    'coef': res['lasso_cv'].coef_,\n",
    "    'abs_coef': np.abs(res['lasso_cv'].coef_)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the features based on the absolute value of the coefficients\n",
    "feat_coef_df = feat_coef_df.sort_values(by='abs_coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feat_type(feat_coef_df):\n",
    "    feat_coef_df['feat_type'] = 'Others'\n",
    "    feat_coef_df['feat_type'] = np.where(\n",
    "        feat_coef_df['feat_name'].apply(lambda x: 'Pool' in x),\n",
    "        'Pool', feat_coef_df['feat_type']\n",
    "    )\n",
    "    \n",
    "    feat_coef_df['feat_type'] = np.where(\n",
    "        feat_coef_df['feat_name'].apply(lambda x: ('Area' in x and 'Pool' not in x) or ('SF' in x) or ('GarageCars' == x)),\n",
    "        'Area / Size', feat_coef_df['feat_type']\n",
    "    )\n",
    "    \n",
    "    feat_coef_df['feat_type'] = np.where(\n",
    "        feat_coef_df['feat_name'].apply(lambda x: 'Zoning' in x or 'Neighborhood' in x),\n",
    "        'Location', feat_coef_df['feat_type']\n",
    "    )\n",
    "    \n",
    "    return feat_coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54428f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coef_df = add_feat_type(feat_coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rank_1 = (\n",
    "    p9.ggplot(\n",
    "        feat_coef_df.head(25),\n",
    "        p9.aes(x='reorder(feat_name, abs_coef)', y='abs_coef', fill='feat_type'))\n",
    "    + p9.geom_bar(stat='identity')\n",
    "    + p9.ylab('Absolute Coefficient')\n",
    "    + p9.xlab('Features')\n",
    "    + p9.coords.coord_flip()\n",
    "    + p9.scale_fill_brewer(type='div', palette=4)\n",
    "    + p9.theme(figure_size=(3,4.5), legend_position=(0.7,0.35), legend_background=p9.element_blank())\n",
    ")\n",
    "fig_rank_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1297f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coef_df[\n",
    "    feat_coef_df.apply(lambda x: 'Pool' in x['feat_name'], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948089b1",
   "metadata": {},
   "source": [
    "**Stability of the coefficients**\n",
    "\n",
    "* Run the algorithm multiple times to assess the stability of the model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_stability = []\n",
    "for i in range(100):\n",
    "    print(i, end=',', flush=True)\n",
    "    \n",
    "    # Use different random seed to run the whole training and prediction process\n",
    "    res_stability.append(\n",
    "        train_and_predict(df_normalized, feats, 'logSalePrice', is_log_transformed=True, random_state=1000 + i*100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coef_repeated_df = pd.DataFrame()\n",
    "\n",
    "# Gather the result for multiple runs of the LASSO\n",
    "for i in range(100):\n",
    "    current_res = res_stability[i]\n",
    "    \n",
    "    temp_df = pd.DataFrame({\n",
    "            'run_id': i,\n",
    "            'feat_name': current_res['lasso_cv'].feature_names_in_,\n",
    "            'coef': current_res['lasso_cv'].coef_,\n",
    "            'abs_coef': np.abs(current_res['lasso_cv'].coef_)\n",
    "    })\n",
    "    \n",
    "    feat_coef_repeated_df = feat_coef_repeated_df.append(temp_df)\n",
    "\n",
    "# Aggregate the feature coefficients\n",
    "feat_coef_summary_df = feat_coef_repeated_df.groupby('feat_name').agg({\n",
    "    'coef': [np.mean, np.min, np.max],\n",
    "    'abs_coef': [np.mean, np.min, np.max]\n",
    "})\n",
    "feat_coef_summary_df.columns = [\n",
    "    'coef_mean', 'coef_min', 'coef_max',\n",
    "    'abs_coef_mean', 'abs_coef_min', 'abs_coef_max']\n",
    "feat_coef_summary_df.sort_values(by='abs_coef_mean', ascending=False, inplace=True)\n",
    "feat_coef_summary_df.reset_index(inplace=True)\n",
    "feat_coef_summary_df['rank'] = np.arange(1, len(feat_coef_summary_df) + 1)\n",
    "\n",
    "feat_coef_summary_df = add_feat_type(feat_coef_summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89f379",
   "metadata": {},
   "source": [
    "Now, the mean coefficients from multiple run is more stable\n",
    "* PoolArea ranks # 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rank_100 = (\n",
    "    p9.ggplot(\n",
    "        feat_coef_summary_df.head(25),\n",
    "        p9.aes(x='reorder(feat_name, abs_coef_mean)', y='abs_coef_mean', fill='feat_type'))\n",
    "    + p9.geom_bar(stat='identity')\n",
    "    + p9.ylab('Absolute Coefficient')\n",
    "    + p9.xlab('Features')\n",
    "    + p9.coords.coord_flip()\n",
    "    + p9.scale_fill_brewer(type='div', palette=4)\n",
    "    + p9.theme(figure_size=(3,4.5), legend_position=(0.7,0.35), legend_background=p9.element_blank())\n",
    ")\n",
    "fig_rank_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use boxplot to show the spread of the feature coefficients\n",
    "\n",
    "top_feats = feat_coef_summary_df.head(50)['feat_name']\n",
    "\n",
    "(\n",
    "    p9.ggplot(\n",
    "        feat_coef_repeated_df[feat_coef_repeated_df['feat_name'].isin(top_feats)],\n",
    "        p9.aes(x='feat_name', y='abs_coef')\n",
    "    )\n",
    "    + p9.geom_boxplot()\n",
    "    + p9.stat_summary(\n",
    "        fun_y=np.mean, geom=\"point\", size=1, color=\"red\", fill=\"red\")\n",
    "    + p9.scale_x_discrete(limits=top_feats[-1::-1])\n",
    "    + p9.coord_flip()\n",
    "    + p9.ylab('Absolute Coefficients')\n",
    "    + p9.xlab('Feature Name')\n",
    "    + p9.theme(figure_size=(6, 10))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff03b885",
   "metadata": {},
   "source": [
    "Create a data frame to contain all feature ranking / coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coef_df['method'] = 'One Run'\n",
    "feat_coef_summary_df['method'] = 'Repeated 100 Runs'\n",
    "feat_coef_both_df = feat_coef_summary_df[[\n",
    "    'feat_name', 'coef_mean', 'abs_coef_mean', 'feat_type', 'method'\n",
    "]].head(25).copy().rename(\n",
    "    columns={'coef_mean': 'coef', 'abs_coef_mean': 'abs_coef'}\n",
    ")\n",
    "feat_coef_both_df['feat_name'] = feat_coef_both_df['feat_name'].apply(lambda x: ' ' + x)\n",
    "\n",
    "feat_coef_both_df = feat_coef_both_df.append(feat_coef_df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    p9.ggplot(\n",
    "        feat_coef_both_df,\n",
    "        p9.aes(\n",
    "            x='reorder(feat_name, abs_coef)',\n",
    "            y='abs_coef',\n",
    "            fill='feat_type',\n",
    "            group='method'\n",
    "        )\n",
    "    )\n",
    "    + p9.geom_bar(stat='identity')\n",
    "    + p9.ylab('Absolute Coefficient')\n",
    "    + p9.xlab('Features')\n",
    "    + p9.coords.coord_flip()\n",
    "    + p9.scale_fill_brewer(type='div', palette=4)\n",
    "    + p9.facet_wrap('~method', scales='free_y')\n",
    "    + p9.theme(\n",
    "        figure_size=(9,5.5),\n",
    "        legend_position=(1,0.5),\n",
    "        # legend_background=p9.element_blank(),\n",
    "        subplots_adjust={'wspace':0.56}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e32f247",
   "metadata": {},
   "source": [
    "**5.4 the Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d5df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from \"YrSold\" one-hot encoded features\n",
    "YrSold_feat_coef_df = feat_coef_repeated_df[[\n",
    "    'YrSold' in x for x in feat_coef_repeated_df.feat_name\n",
    "]]\n",
    "\n",
    "YrSold_feat_coef_df['year'] = YrSold_feat_coef_df['feat_name'].apply(lambda x: x[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: baseline is 2006, which is not encoded as a new feature\n",
    "(\n",
    "    p9.ggplot(YrSold_feat_coef_df, p9.aes('year', 'coef', fill='year'))\n",
    "    + p9.geom_boxplot()\n",
    "    + p9.geom_hline(yintercept=0, color='r')\n",
    "    + p9.xlab('Feature Name / Year Sold')\n",
    "    + p9.ylab('Coefficients')\n",
    "    # + p9.ggtitle('Feature Coef. for Different YearSold')  # remove title for latex report\n",
    "    + p9.theme(figure_size=(3, 3), legend_position='none')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa72452",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* The coef for YrSold_2009 is only slightly lower than the coef for other years. It seems the house market was not heavily impacted by the crisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0fc37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97898064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow = pd.read_csv('data/zillow_price_state.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cba0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_price_change = (\n",
    "    df_zillow.loc[:, '2006-01-31':'2011-01-31']  # Only look at the years around the financial crisis\n",
    "    .apply(lambda x: x/x['2006-01-31'] - 1, axis=1)  # Use 2006-01-31 price as the baseline of calculation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e386f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the price change data back to zillow data, and remove the original price data\n",
    "df_zillow = pd.concat([df_zillow.iloc[:, :5], df_zillow_price_change], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow = (\n",
    "    df_zillow.melt(\n",
    "        id_vars=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName'],\n",
    "        var_name='dt',\n",
    "        value_name='price_change'\n",
    "    )\n",
    ")\n",
    "\n",
    "df_zillow['dt'] = df_zillow['dt'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c691d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    p9.ggplot(\n",
    "        df_zillow[df_zillow['StateName'].isin(['IA', 'CA'])],\n",
    "        p9.aes('dt', 'price_change', color='StateName')\n",
    "    )\n",
    "    + p9.geom_line(size=1)\n",
    "    + p9.scale_x_datetime(breaks=date_breaks('6 months'), labels=date_format('%b %Y')) \n",
    "    + p9.scale_y_continuous(labels=lambda l: ['{:.0%}'.format(x) for x in l])\n",
    "    + p9.scale_color_brewer(type='qual', palette=2)\n",
    "    + p9.xlab('Date')\n",
    "    + p9.ylab('Price Change (Relative to Jan 2006)')\n",
    "    # + p9.ggtitle('House Price Change Around the Financial Crisis in 2008')\n",
    "    + p9.theme(\n",
    "        figure_size=(4, 3),\n",
    "        axis_text_x=p9.element_text(rotation=30, hjust=1),\n",
    "        legend_position=(0.75, 0.55),\n",
    "        legend_background=p9.element_blank()\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
